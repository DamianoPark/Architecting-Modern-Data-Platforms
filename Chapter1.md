


# 1장. 빅데이터 기술 기초 다지기
> 아파치 하둡이란? 
- 높은 확장성과 신뢰성을 보유한 분산 스토리지와 분산처리 기능을 제공하는 에코 시스템
- 수평 확장 가능한 아키텍처
- HDFS (Hadoop Distributed File System) + YARN(Yet Another Resource Negotiator) 
	- HDFS : 분산 파일 시스템 
	- YARN : 분산 서버 클러스터 환경에서 프로세스 실행
		-  +)어플리케이션)  Map Reduce

---
## 핵심 컴포넌트 
### HDFS
-  특징 
	- 확장성과 장애 허용성을 가진 분산 파일 시스템
	- 순차 접근 방식을 통해 디스크에 불변 데이터를 저장하는 것에 최적화
- 데이터 저장
	- 블록 단위 : 128 MB
	- 여러대의 서버에 복제본 저장
		- 워커노드(클러스터) -> 데이터 노드 -> 데몬 ---블록 전달---> 로컬디스크 저장
			- 네임노드(마스터 서버) :  파일 메타 데이터 관리
			- 데이터 노드 : 데이터 저장 + 데이터 제공

	<center><img  src="https://hadoop.apache.org/docs/r1.2.1/images/hdfsarchitecture.gif" height="300"></center>
	
	- 저장 순서 
		1. 클라이언트는 네임 노드를 통해 블록이 저장될 데이터 노드 목록 받음
		2. 클라이언트는 첫번째 데이터 노드에 블록을 쓰고, 차례로 다음 노드로 데이터를 보냄
		3. 네임 노드는 데이터 노드의 상황을 고려하여 파이프라인을 구성할 데이터 노드 결정
		4. 네임 노드는 최소 두개의 다른 렉에 각 블록을 저장
	- 읽을때 
		- 클라이언트는 네임노드를 통해 읽을 블록을 갖은 데이터 노드 목록 받음
		- 네트워크 관점에서 가장 가까운 데이터 노드로 부터 데이터 읽음
	- 장애 발생시
		- 데이터 노드에 장애 발생
			- 네임 노드는 당애 데이터 노드에 저장된 데이터 블록 목록 파악
			- 복제 계수 충족하도록 다른 데이터 노드에 복사하도록 지시



### YARN
- 중앙 클러스터 매니저 
	- 가용 연산 자원의 용량과 필요한 워크로드를 관리
- 각 워커노드에 `노드매니저`데몬 실행
	- `노드매니저` : 
		- 리소스매니저( 마스터 프로세스)에 정보 보고
		- 연산자원 + 잔여 메모리 보고
			- 가용자원 : 컨테이너 형태로 분할되어 제공 (가상코어 방식)
	- 프레임워크 특성
		- 클러스터에 분산되어 연산을 수행하는 어플리케이션을 실행



### 아파치 주키퍼

<center><img src="https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99C327405BF7AC410B" height =250 ><center>

- 하둡 에코시스템에 사용되는 분산 설정 서비스 
	- 설정데이터 -> 파일시스템 & 지노드(노드트리) 에 저장
		- 지노드 : 데이터 존재
	- 클라이언트 ---linked with--- 주키퍼  
		- 지노드 CRUD 가능
- 회복성
	- 앙상블로서 각기 다른 서버에 배포
		- 다수결 원칙을 위해 홀수의 서버에 배포
			- 쿼럼 : 과반수 서버 그룹
		- 1 리더 / 나머지 팔로워
			- 데이터 저장시 : 팔로워 -> 리더 서버로 전달 (데이터 일관성 보장을 위해)


### 아파치 하이브 메타스토어

- 정형 데이터 관리
- 하이브 테이블 : 
	- 관계형 데이터 베이스의 거의 모든 타입 지원
- 스키마 온 리드 : 
	- 스키마 요건이 런타임에만 검사 
- 메타스토어 : 관리형 테이블 / 외부 테이블 지원 
	- 관리형 테이블 : 스토리지 엔진에 저장된 데이터를 하이브가 능동적으로 제어
		- 테이블 생성 -> 스토리지 엔진에 테이블 구조 생성 (HDFS에 디렉토리 생성)
		- 테이블 삭제 -> 스토리지 엔진에 저장된 데이터 모두 삭제
	- 외부 테이블 : 
		- 메타데이터 변경시, 스토리지 엔진에 저장된 데이터를 수정하지 않음
		- 데이터 베이스에 있는 메타데이터만 관리


---
## 연산 프레임워크

### 하둡 멥리듀스
> 연산의 단계	 :	 맵 / 셔플 / 리듀스  
- [맵]
	- HDFS에서 읽은 데이터가 다수의 맵 태스크로 나뉘어 병렬처리  
	- map() 사용자 정의 함수 : 파일에 있는 각 레코드를 `key-value`형태로 반환
- [셔플]
	- `key-value` 결과물이 리듀스 태스크 입력값으로 전달
- [리듀스]
	- reduce() 사용자 정의 함수 : 하나의 키에 대한 여러 값 집계 or 결합
	
	<center><img src ="https://t1.daumcdn.net/cfile/tistory/2136A84B59381A8428"><center>
	
- 단점
	- 복잡한 파이프라인에서 사용 어려움
	- 반복 연산시 컴퓨팅 비용 과다
	- 이후 프레임워크에서 효율화됨


### 아파치 스파크
> 효율성 & 사용성에 초점을 둔 분산 연산 프레임워크
- 필터링, 조인, 그룹핑 등의 연산 API 사용 가능
- 설계의 주요 목표 : 워커노드의 메모리 최대 활용
- 스트림 프로세싱 구현 : 데이터 셋에 대한 마이크로 배치 주기 실행 방식
	- 배치 / 스트리밍 모드에서 적용되는 변환에 사용되는 코드를 비슷하게 사용 가능
- 머신러닝용 라이브러리 API 제공
	- Spark MLlib => Data Cleansing, Feature Extraction , Algorithm 실행 가능
	- 데이터 프로세싱 분야의 강력한 프레임워크
		- 배치 프로세싱, 머신러닝, 스트리밍 작업 시 표준으로 이용


## 분석용 SQL엔진
맵리듀스와 스파크가 강력한 프레임워크이지만 , 자바나 파이썬 + 코드 배포 운영 Skill 필요  => SQL 과 비슷한 인터페이스 필요 부각

### 아파치 하이브
> 하둡용 데이터 Warehousing 기술
HDFS에 저장된 정형 데이터를 SQL 형식의 `HIVE QL`로 쿼리할 수 있게한 최초의 기술 ( made by Facebook) 

- 쿼리 기능
	- 하이브 서버2 로 SQL 쿼리 실행가능
		- 쿼리 서버 세션 생성 ->  쿼리 전송 -> 파싱 -> Batch 작업으로 컴파일
	- 맵리듀스 작업 연쇄 실행을 통해 처리
		- 많은 시간이 소요되므로 ETL(Extract, Transform, Load) 등의 오프라인 배치 작업에 적합
- 하이브 기반 워크 플로 : 높은 신뢰성


### 아파치 임팔라
> 대규모 병렬 처리 엔진 : 하둡-클라우드 스토리지에 저장된 대용량 데이터 셋에 대한 **고속, 대화형** SQL 엔진
- 테라바이트 데이터에 대한 동시실행 쿼리 등을 빠르게 처리하는 것이 목표
- 임팔라 데몬 (C++ 기반) 워크프로세스로 구현됨
- 중앙 쿼리 서버가 없이 `코디네이터 노드`로 동작
	- 코디네이터 ---쿼리---> 임팔라 ---컴파일---> 분산쿼리계획
		- 분산쿼리계획 : `
			- `Fragment` 로 나뉘는 연산자 트리로 구성
			- 트리내에서 실행되는 연산 모음
	- 클라이언트 ---쿼리--->데몬(코디네이터) ---쿼리 Fragment Instance---> 클러스터 내 다른 데몬 ---> 쿼리 수행



## 스토리지 엔진
원조 스토리지 엔진인 HDFS 
순차 스캔으로 접근되어 삭제가 안되고 추가가 가능한 데이터를 저장하는데에 탁월
검색, 수정, 분석을 위한 엔진의 필요성 대두


### 아파치 HBase
> HBase : Random-Access 가능한 키-값 구조의 반정형 데이터를 HDFS에 저장 
- NO 관계형 데이터 스토어
- `Cell`이라 불리는 키-값 쌍의 반정형 데이터 형식으로 데이터 저장

- 키 
	- Row Key : 키의 첫번째 부분
		- 셀의 논리적인 그룹인 로우를 정의 하는데 사용
	- Column Family : 키의 나머지 부분 (역시 논리적 그룹 정의)
		- 컬럼 한정자 : 하나의 row에 수백만개의 한정자 존재 가능
- 타임스탬프
	- 셀의 버전을 나타냄

- 키의 구성요소에 따라 Cell 저장
	- 로우키 기준 -> 컬럼 패밀리 -> 컬럼 한정자 -> 타임스탬프  기준으로 정렬

- 테이블 레이아웃의 설계가 중요 


### 아파치 쿠두
> 빠른 임의 접근 일기를 지원하려면 여러 스토리지 엔진을 사용해야함에 따라 . 데이터 입수 & 오케이스트레이션 파이프라인이 복잡해졌다

>  임의 접근 & 순차 스캔 모두 지원하는 스토리지&쿼리 엔진 개발

- 쿠두 : 
	- 정의된 스키마를 따르는 테이블에 타입을 가진 컬럼으로 구성된 레코드를 저장하는 정형 데이터 스토어 
 
 - 파티셔닝 매커니즘 
	 - 범위 파티셔닝 
	 - 해시 파티셔닝 
	- 이 둘을 조합한  멀티 레벨 파티셔닝도 가능 


### 아파치 솔라
> 비정형 or 반정형 데이터에 대한 유연한 검색 필요시 
> `아파치 솔라` & `엘라스틱 서치` => 엔터프라이즈 검색용 기술
- 다양한 검색위해 역방향 인덱스 사용
	- 매칭되는 도큐먼트 목록에 용어를 매핑
		- 용어 : 단어, 스템, 범위, 숫자, 표
	- 도큐먼트는 필드를 포함
		- 필드 : 용어 타입 정의 
			- 개별 토큰 분리 가능
			- 각 필드별 인덱스 정의 가능
			- 도큐 먼트 포함되는 필드는 스키마로 정의 

### 아파치 카프카
> 스트리밍 데이터 : 빅데이터 처리 수요를 감당할 확장성 확보가 어려움
> 폭발적으로 입수되는 스트림이나 장애를 해결하기위해 개발됨 

> 읽기/쓰기 대역폭을 수평적으로 확장할수 있도록 설계된 발행/구독 시스템
- 메시지를 순차적 로그로 저장
- 클라이언트는 숫자형태의 Offset을 이용하여 특정지점으로부터 데이터 가져옴

- 데이터 구조
	- 토픽 
		- 여러대의 서버에 분산되는 메시지
		- 여러개의 파티션으로 분할 가능
	- 메시지
		- 바이트 배열의 키/값 쌍
		- 클라이언트는 프로듀서를 통해 카프카 토픽의 파티션으로 메세지 발행
		- 순차적 증가하는 오프셋
- 클라이언트는 컨슈머를 통해 데이터 읽기 가능
	- 여러 컨슈머를 그룹으로 묶을수 있음
	- 마지막 데이터 읽기 성공했을 때의 오프셋을 컨슈머는 알고있으므로, 그 다음 오프셋 데이터 부터 누락 없이 다시 읽을 수 있음

- 빅데이터 플랫폼 주요 기술


## 데이터 입수
- 아파치 스쿱 : 데이터 베이스 내 데이터 가져오기 / 내보내기
- 아피치 나이파이
- 스트림셋 데이터 컬렉터


## 오케스트레이션
### 아파치 우지

 
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTExNzY1NDY5ODAsLTExMjY1MDk3MTAsLT
E1NTY5MzYzNDcsMTg2MjM1NzgwOCwtMzQwMjM3ODMwXX0=
-->
